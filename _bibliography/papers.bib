---
---

@inproceedings{ma2025spatialreasoner,
  title={SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning},
  author={Ma, Wufei and Chou, Yu-Cheng and Liu, Qihao and Wang, Xingrui and Melo, Celso M de and Xie, Jianwen and Yuille, Alan},
  booktitle={Advances in Neural Information Processing Systems},
  volume={38},
  year={2025},
  preview={spatialreasoner.png},
  abstract={We introduce SpatialReasoner, a novel large vision-language model (LVLM) that address 3D spatial reasoning with explicit 3D representations shared between stages -- 3D perception, computation, and reasoning. Explicit 3D representations provide a coherent interface that supports advanced 3D spatial reasoning and enable us to study the factual errors made by LVLMs.},
  website={https://spatial-reasoner.github.io},
  arxiv={2504.20024},
  area_3d_vision={true},
  area_vl={true},
  selected={true},
}

@inproceedings{Ma_2025_ICCV,
  author={Ma, Wufei and Chen, Haoyu and Zhang, Guofeng and Melo, Celso M de and Chen, Jieneng and Yuille, Alan},
  title={3DSRBench: A Comprehensive 3D Spatial Reasoning Benchmark},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  month={October},
  year={2025},
  preview={3dsrbench.png},
  abstract={We present 3DSRBench, a comprehensive 3D spatial reasoning benchmark.},
  arxiv={2412.07825},
  website={https://3dsrbench.github.io},
  selected={true},
  area_3d_vision={true},
  area_vl={true}
}

@article{wang2024compositional,
  title={DINeMo: Learning Neural Mesh Models with no 3D Annotations},
  author={Guo, Weijie and Zhang, Guofeng and Ma, Wufei and Yuille, Alan},
  journal={3rd Workshop on Compositional 3D Vision at CVPR},
  year={2025},
  preview={dinemo.jpg},
  abstract={We present DINeMo, a novel neural mesh model that is trained with no 3D annotations by leveraging pseudo-correspondence obtained from large visual foundation models.},
  website={https://analysis-by-synthesis.github.io/DINeMo/},
  arxiv={2503.20220},
  area_3d_vision={true},
}

@inproceedings{ma2025spatialllm,
  title={SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models},
  author={Ma, Wufei and Ye, Luoxin and Melo, Celso M de and Chen, Jieneng and Yuille, Alan},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  year={2025},
  preview={3dvlm-teaser2-2.jpg},
  abstract={We systematically study the impact of 3D-informed data, architecture, and training setups and present SpatialLLM, an LMM with advanced 3D spatial reasoning abilities.},
  website={https://3d-spatial-reasoning.github.io/spatial-llm/},
  area_vl={true},
  area_3d_vision={true},
  selected={true},
  highlight={(Highlight, 3.0%)},
  arxiv={2505.00788},
}

@inproceedings{wang2025pulsecheck457,
  title={Spatial457: A Diagnostic Benchmark for Comprehensive Spatial Reasoning of Large Multimodal Models},
  author={Wang, Xingrui and Ma, Wufei and Zhang, Tiezheng and Melo, Celso M de and Chen, Jieneng and Yuille, Alan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2025},
  preview={pulsecheck.png},
  abstract={We present PulseCheck457, a scalable and unbiased synthetic dataset designed with 4 key capability for spatial reasoning.},
  arxiv={2502.08636},
  area_vl={true},
  area_dataset={true},
  area_3d_vision={true},
  highlight={(Highlight, 3.0%)},
  website={https://xingruiwang.github.io/projects/Spatial457/},
}

@inproceedings{wang2024compositional,
  title={Compositional 4D Dynamic Scenes Understanding with Physics Priors for Video Question Answering},
  author={Wang, Xingrui and Ma, Wufei and Wang, Angtian and Chen, Shuo and Kortylewski, Adam and Yuille, Alan},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025},
  preview={superclevr_phy.png},
  abstract={We develop a video question answering dataset and study the dynamics properties of objects.},
  arxiv={2406.00622},
  area_3d_vision={true},
  area_dataset={true},
  area_vl={true}
}

@inproceedings{ma2024imagenet3d,
  title={ImageNet3D: Towards General-Purpose Object-Level 3D Understanding},
  author={Ma, Wufei and Zhang, Guofeng and Liu, Qihao and Zeng, Guanning and Kortylewski, Adam and Liu, Yaoyao and Yuille, Alan},
  booktitle={Advances in Neural Information Processing Systems},
  year={2024},
  volume={37},
  preview={imagenet3d_logo.png},
  arxiv={2406.09613},
  abstract={We present ImageNet3D, a large dataset for general-purpose object-level 3D understanding.},
  code={https://github.com/wufeim/imagenet3d_exp},
  data={https://github.com/wufeim/imagenet3d},
  website={https://imagenet3d.github.io},
  selected={true},
  area_dataset={true},
  area_3d_vision={true}
}

@inproceedings{ma2024rethinking,
  title={Rethinking Video-Text Understanding: Retrieval from Counterfactually Augmented Data},
  author={Ma, Wufei and Li, Kai and Jiang, Zhongshi and Meshry, Moustafa and Liu, Qihao and Wang, Huiyu and H{\"a}ne, Christian and Yuille, Alan},
  booktitle={European Conference on Computer Vision},
  year={2024},
  organization={Springer},
  preview={feint6k.png},
  abstract={We propose a novel task, retrieval from counterfacually augmented data, and a dataset, Feint6K, for video-text understanding.},
  website={https://feint6k.github.io},
  data={https://github.com/facebookresearch/feint6k},
  selected={true},
  area_vl={true},
  area_dataset={true},
  arxiv={2407.13094},
  highlight={(Strong Double Blind)}
}

@inproceedings{jesslen2024novum,
  title={NOVUM: Neural Object Volumes for Robust Object Classification},
  author={Jesslen, Artur and Zhang, Guofeng and Wang, Angtian and Ma, Wufei and Yuille, Alan and Kortylewski, Adam},
  booktitle={European Conference on Computer Vision},
  year={2024},
  organization={Springer},
  preview={rcnet.png},
  abstract={We introduce NOVUM, a 3D compositional model for 3D-aware image classification.},
  arxiv={2305.14668},
  area_3d_vision={true}
}

@article{ma2024uncertainty,
  title={Uncertainty-Aware Deep Video Compression with Ensembles},
  author={Ma, Wufei and Li, Jiahao and Li, Bin and Lu, Yan},
  journal={IEEE Transactions on Multimedia},
  year={2024},
  publisher={IEEE},
  preview={tmm_eg.png},
  abstract={We propose an uncertainty-aware video compression model that effectively captures the predictive uncertainty with deep ensembles and saves bits by more than 20% when compared to DVC Pro.},
  arxiv={2403.19158},
  journal_page={https://ieeexplore.ieee.org/document/10461131},
  area_compression={true}
}

@inproceedings{ma2024generating,
  title={Generating Images with 3D Annotations Using Diffusion Models},
  author={Wufei Ma* and Qihao Liu* and Jiahao Wang* and Angtian Wang and Xiaoding Yuan and Yi Zhang and Zihao Xiao and Guofeng Zhang and Beijia Lu and Ruxiao Duan and Yongrui Qi and Adam Kortylewski and Yaoyao Liu and Alan Yuille},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
  url={https://openreview.net/forum?id=XlkN11Xj6J},
  preview={3ddst_compressed.png},
  abstract={We propose 3D-DST that generates synthetic data with 3D groundtruth by incorporating 3D geomeotry control into diffusion models. With our diverse prompt generation, we effectively improve both in-distribution (ID) and out-of-distribution (OOD) performance for various 2D and 3D vision tasks.},
  arxiv={2306.08103},
  code={https://github.com/wufeim/DST3D},
  area_dataset={true},
  area_3d_vision={true},
  highlight={(Spotlight, 5%)},
  annotation={* equal contribution},
  selected={true}
}

@inproceedings{wang20243d,
  title={3d-aware visual question answering about parts, poses and occlusions},
  author={Wang, Xingrui and Ma, Wufei and Li, Zhuowan and Kortylewski, Adam and Yuille, Alan},
  booktitle={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023},
  preview={3dvqa.png},
  abstract={We introduce Super-CLEVR-3D, a compositional reasoning dataset that contains questions about object parts, their 3D poses, and occlusions. We propose PO3D-VQA, a 3D-aware VQA model that combines probabilistic neural symbolic program execution with 3D generative representations of objects.},
  arxiv={2310.17914},
  code={https://github.com/XingruiWang/3D-Aware-VQA},
  area_dataset={true},
  area_3d_vision={true},
  area_vl={true}
}

@inproceedings{wang2024neural,
  title={Neural textured deformable meshes for robust analysis-by-synthesis},
  author={Wang*, Angtian and Ma*, Wufei and Yuille, Alan and Kortylewski, Adam},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3108--3117},
  year={2024},
  preview={deformable_nemo.png},
  abstract={We introduce Neural Textured Deformable Meshes (NTDM), which learns a neural mesh model with deformable geometry and enables optimization on both camera parameters and object geometries.},
  arxiv={2306.00118},
  area_3d_vision={true},
  annotation={* equal contribution}
}

@inproceedings{yang2024robust,
  title={Robust Category-Level 3D Pose Estimation from Diffusion-Enhanced Synthetic Data},
  author={Yang, Jiahao and Ma, Wufei and Wang, Angtian and Yuan, Xiaoding and Yuille, Alan and Kortylewski, Adam},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3446--3455},
  year={2024},
  preview={synthetic_nemo.png},
  abstract={We introduce SyntheticP3D, a synthetic dataset for object pose estimation, and CC3D that adapts neural mesh models from synthetic to real data.},
  arxiv={2305.16124},
  area_3d_vision={true}
}

@inproceedings{xu2023animal3d,
  title={Animal3D: A Comprehensive Dataset of 3D Animal Pose and Shape},
  author={Xu, Jiacong and Zhang, Yi and Peng, Jiawei and Ma, Wufei and Jesslen, Artur and Ji, Pengliang and Hu, Qixin and Zhang, Jiehua and Liu, Qihao and Wang, Jiahao and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9099--9109},
  year={2023},
  preview={animal3d_sm.png},
  abstract={Animal3D consists of 3379 images collected from 40 mammal species, high-quality annotations of 26 keypoints, and importantly the pose and shape parameters of the SMAL model.},
  arxiv={2308.11737},
  html={https://xujiacong.github.io/Animal3D/},
  data={https://drive.google.com/drive/folders/17KRe8Z7jCZNDeBu45Wx2zS8Yh2tV_t2v?usp=sharing},
  area_dataset={true},
  area_3d_vision={true}
}

@article{zhao2023ood,
  title={OOD-CV-v2: An Extended Benchmark for Robustness to Out-of-Distribution Shifts of Individual Nuisances in Natural Images},
  author={Zhao, Bingchen and Wang, Jiahao and Ma, Wufei and Jesslen, Artur and Yang, Siwei and Yu, Shaozuo and Zendel, Oliver and Theobalt, Christian and Yuille, Alan and Kortylewski, Adam},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  preview={oodcv_v2.png},
  abstract={We introduce OOD-CV-v2, a benchmark dataset that includes out-of-distribution examples of 10 object categories in terms of pose, shape, texture, context and the weather conditions, and enables benchmarking of models for image classification, object detection, and 3D pose estimation.},
  arxiv={2304.10266},
  html={https://bzhao.me/OOD-CV/},
  area_dataset={true},
  area_3d_vision={true}
}

@inproceedings{li2023super,
  title={Super-CLEVR: A Virtual Benchmark to Diagnose Domain Robustness in Visual Reasoning},
  author={Li, Zhuowan and Wang, Xingrui and Stengel-Eskin, Elias and Kortylewski, Adam and Ma, Wufei and Van Durme, Benjamin and Yuille, Alan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14963--14973},
  year={2023},
  preview={superclevr_eg.png},
  abstract={We introduce Super-CLEVR, where different factors in VQA domain shifts can be isolated in order that their effects can be studied independently. We propose probabilistic NSVQA (P-NSVQA), which extends NSVQA with uncertainty reasoning.},
  arxiv={2212.00259},
  code={https://github.com/Lizw14/Super-CLEVR},
  area_dataset={true},
  area_vl={true},
  highlight={(Highlight)}
}

@inproceedings{ma2022robust,
  title={Robust Category-Level 6D Pose Estimation with Coarse-to-Fine Rendering of Neural Features},
  author={Ma, Wufei and Wang, Angtian and Yuille, Alan and Kortylewski, Adam},
  booktitle={European Conference on Computer Vision},
  pages={492--508},
  year={2022},
  organization={Springer},
  preview={eccv22_6dpose_small.png},
  abstract={We introduce a coarse-to-fine optimization strategy that utilizes the neural features to estimate a sparse set of 6D object proposals, which are subsequently refined with gradient-based optimization.},
  arxiv={2209.05624},
  code={https://github.com/wufeim/6d_pose_eccv22},
  area_3d_vision={true},
}

@inproceedings{zhao2022ood,
  title={OOD-CV: A Benchmark for Robustness to Out-of-Distribution Shifts of Individual Nuisances in Natural Images},
  author={Zhao, Bingchen and Yu, Shaozuo and Ma, Wufei and Yu, Mingxin and Mei, Shenxiao and Wang, Angtian and He, Ju and Yuille, Alan and Kortylewski, Adam},
  booktitle={European conference on computer vision},
  pages={163--180},
  year={2022},
  organization={Springer},
  preview={robin2.png},
  abstract={We introduce OOD-CV, a benchmark dataset for diagnosing the robustness of 2D and 3D vision algorithms to individual nuisances in real-world images.},
  arxiv={2111.14341},
  area_dataset={true},
  area_3d_vision={true},
  highlight={(Oral)}
}

@inproceedings{mohsin2021making,
  title={Making group decisions from natural language-based preferences},
  author={Mohsin, Farhad and Luo, Lei and Ma, Wufei and Kang, Inwon and Zhao, Zhibing and Liu, Ao and Vaish, Rohit and Xia, Lirong},
  booktitle={Proceedings of the 8th International Workshop on Computational Social Choice (COMSOC)},
  pages={2},
  year={2021},
  preview={pub-3.png},
  abstract={We propose a framework for making group decisions from natural language-based preferences. Experiments on the real world data confirms the efficacy of our method.},
  pdf={PT_Paper_78.pdf},
  data={https://github.com/farhadmohsin/CollegeConfidentialComparativeDisucssions},
  journal_page={https://comsoc2021.net.technion.ac.il/accepted-papers/},
  area_dataset={true},
  area_preference={true}
}

@article{ma2020image,
  title={Image-driven discriminative and generative machine learning algorithms for establishing microstructure--processing relationships},
  author={Ma, Wufei and Kautz, Elizabeth J and Baskaran, Arun and Chowdhury, Aritra and Joshi, Vineet and Yener, Bulent and Lewis, Daniel},
  journal={Journal of Applied Physics},
  volume={128},
  number={13},
  year={2020},
  publisher={AIP Publishing},
  preview={pub-2.png},
  abstract={Characterize 10 different microstructure representations with image texture features and quantitative metrics from image segmentation. For the microstructure generation task, two schemes are considered: 1) generating high-resolution (1024x1024) microstructure images from random noise; and 2) train a style transfer GAN for image generation conditioned on the segmentation label.},
  arxiv={2007.13417},
  html={https://wufeim.github.io/microstructure-characterization-II/},
  code={https://github.com/wufeim/microstructure-characterization-II},
  journal_page={https://aip.scitation.org/doi/full/10.1063/5.0013720},
  area_microstructure={true}
}

@article{kautz2020image,
  title={An image-driven machine learning approach to kinetic modeling of a discontinuous precipitation reaction},
  author={Kautz, Elizabeth and Ma, Wufei and Jana, Saumyadeep and Devaraj, Arun and Joshi, Vineet and Yener, B{\"u}lent and Lewis, Daniel},
  journal={Materials Characterization},
  volume={166},
  pages={110379},
  year={2020},
  publisher={Elsevier},
  preview={pub-1.png},
  abstract={Kinetic modeling of a discontinuous precipitation reaction (5 phases) by 1) deep learning with CNN, and 2) performing image segmentation of various microstructure and quantizing the area fractions.},
  arxiv={1906.05496},
  code={https://github.com/wufeim/microstructure-characterization},
  journal_page={https://www.sciencedirect.com/science/article/pii/S1044580319311027},
  area_microstructure={true}
}

@article{baskaran2021adoption,
  title={Adoption of Image-Driven Machine Learning for Microstructure Characterization and Materials Design: A Perspective},
  author={Baskaran, Arun and Kautz, Elizabeth J and Chowdhary, Aritra and Ma, Wufei and Yener, Bulent and Lewis, Daniel},
  journal={JOM},
  volume={73},
  pages={3639--3657},
  year={2021},
  publisher={Springer},
  preview={material_perspective.png},
  abstract={We first review the application of image-driven machine learning approaches to the field of materials characterization. Then we analyze and discuss the impact of various approaches at each step of the experiments.},
  arxiv={2105.09729},
  journal_page={https://link.springer.com/article/10.1007/s11837-021-04805-9},
  area_microstructure={true}
}
