<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Wufei Ma </title> <meta name="author" content="Wufei Ma"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://wufeim.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Wufei</span> Ma </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/feint6k-480.webp 480w,/assets/img/publication_preview/feint6k-800.webp 800w,/assets/img/publication_preview/feint6k-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/feint6k.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="feint6k.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ma2024rethinking" class="col-sm-9"> <div class="title">Rethinking Video-Text Understanding: Retrieval from Counterfactually Augmented Data</div> <div class="author"> <em>Wufei Ma</em>, Kai Li, Zhongshi Jiang, Moustafa Meshry, <a href="https://qihao067.github.io" rel="external nofollow noopener" target="_blank">Qihao Liu</a>, Huiyu Wang, Christian Häne, and <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a> </div> <div class="periodical"> <em>In European Conference on Computer Vision</em> , 2024 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#009f36"> Dataset </abbr> <abbr class="badge rounded" style="background-color:#b509ac"> Vision-Lanugage </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/wufeim/feint6k" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We propose a novel task, retrieval from counterfacually augmented data, and a dataset, Feint6K, for video-text understanding.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/rcnet-480.webp 480w,/assets/img/publication_preview/rcnet-800.webp 800w,/assets/img/publication_preview/rcnet-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/rcnet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="rcnet.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="jesslen2024novum" class="col-sm-9"> <div class="title">NOVUM: Neural Object Volumes for Robust Object Classification</div> <div class="author"> Artur Jesslen, Guofeng Zhang, Angtian Wang, <em>Wufei Ma</em>, <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a>, and <a href="https://adamkortylewski.com" rel="external nofollow noopener" target="_blank">Adam Kortylewski</a> </div> <div class="periodical"> <em>In European Conference on Computer Vision</em> , 2024 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2305.14668" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>We introduce NOVUM, a 3D compositional model for 3D-aware image classification.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/imagenet3d_logo-480.webp 480w,/assets/img/publication_preview/imagenet3d_logo-800.webp 800w,/assets/img/publication_preview/imagenet3d_logo-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/imagenet3d_logo.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="imagenet3d_logo.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ma2024imagenet3d" class="col-sm-9"> <div class="title">ImageNet3D: Towards General-Purpose Object-Level 3D Understanding</div> <div class="author"> <em>Wufei Ma</em>, Guanning Zeng, Guofeng Zhang, <a href="https://qihao067.github.io" rel="external nofollow noopener" target="_blank">Qihao Liu</a>, Letian Zhang, <a href="https://adamkortylewski.com" rel="external nofollow noopener" target="_blank">Adam Kortylewski</a> , Yaoyao Liu, and <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a> </div> <div class="periodical"> <em>arXiv preprint arXiv:2406.09613</em>, 2024 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#009f36"> Dataset </abbr> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2406.09613" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/wufeim/imagenet3d" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We present ImageNet3D, a large dataset for general-purpose object-level 3D understanding.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/superclevr_phy-480.webp 480w,/assets/img/publication_preview/superclevr_phy-800.webp 800w,/assets/img/publication_preview/superclevr_phy-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/superclevr_phy.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="superclevr_phy.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wang2024compositional" class="col-sm-9"> <div class="title">Compositional 4D Dynamic Scenes Understanding with Physics Priors for Video Question Answering</div> <div class="author"> Xingrui Wang, <em>Wufei Ma</em>, Angtian Wang, Shuo Chen, <a href="https://adamkortylewski.com" rel="external nofollow noopener" target="_blank">Adam Kortylewski</a>, and <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a> </div> <div class="periodical"> <em>arXiv preprint arXiv:2406.00622</em>, 2024 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> <abbr class="badge rounded" style="background-color:#b509ac"> Vision-Lanugage </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2406.00622" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>We develop a video question answering dataset and study the dynamics properties of objects.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tmm_eg-480.webp 480w,/assets/img/publication_preview/tmm_eg-800.webp 800w,/assets/img/publication_preview/tmm_eg-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/tmm_eg.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tmm_eg.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ma2024uncertainty" class="col-sm-9"> <div class="title">Uncertainty-Aware Deep Video Compression with Ensembles</div> <div class="author"> <em>Wufei Ma</em>, Jiahao Li, Bin Li, and Yan Lu </div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em>, 2024 </div> <div class="periodical"> </div> <div> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2403.19158" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://ieeexplore.ieee.org/document/10461131" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>We propose an uncertainty-aware video compression model that effectively captures the predictive uncertainty with deep ensembles and saves bits by more than 20% when compared to DVC Pro.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/3ddst_compressed-480.webp 480w,/assets/img/publication_preview/3ddst_compressed-800.webp 800w,/assets/img/publication_preview/3ddst_compressed-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/3ddst_compressed.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="3ddst_compressed.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ma2024generating" class="col-sm-9"> <div class="title">Generating Images with 3D Annotations Using Diffusion Models</div> <div class="author"> <em>Wufei Ma</em>, <a href="https://qihao067.github.io" rel="external nofollow noopener" target="_blank">Qihao Liu</a>, Jiahao Wang, Angtian Wang, Xiaoding Yuan, Yi Zhang, Zihao Xiao, Guofeng Zhang, Beijia Lu, Ruxiao Duan, Yongrui Qi, <a href="https://adamkortylewski.com" rel="external nofollow noopener" target="_blank">Adam Kortylewski</a> , Yaoyao Liu, and <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a> </div> <div class="periodical"> <em>In The Twelfth International Conference on Learning Representations</em> , 2024 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#009f36"> Dataset </abbr> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2306.08103" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/wufeim/DST3D" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We propose 3D-DST that generates synthetic data with 3D groundtruth by incorporating 3D geomeotry control into diffusion models. With our diverse prompt generation, we effectively improve both in-distribution (ID) and out-of-distribution (OOD) performance for various 2D and 3D vision tasks.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/3dvqa-480.webp 480w,/assets/img/publication_preview/3dvqa-800.webp 800w,/assets/img/publication_preview/3dvqa-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/3dvqa.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="3dvqa.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wang20243d" class="col-sm-9"> <div class="title">3d-aware visual question answering about parts, poses and occlusions</div> <div class="author"> Xingrui Wang, <em>Wufei Ma</em>, Zhuowan Li, <a href="https://adamkortylewski.com" rel="external nofollow noopener" target="_blank">Adam Kortylewski</a>, and <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a> </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems</em>, 2024 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#009f36"> Dataset </abbr> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> <abbr class="badge rounded" style="background-color:#b509ac"> Vision-Lanugage </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2310.17914" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/XingruiWang/3D-Aware-VQA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We introduce Super-CLEVR-3D, a compositional reasoning dataset that contains questions about object parts, their 3D poses, and occlusions. We propose PO3D-VQA, a 3D-aware VQA model that combines probabilistic neural symbolic program execution with 3D generative representations of objects.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/deformable_nemo-480.webp 480w,/assets/img/publication_preview/deformable_nemo-800.webp 800w,/assets/img/publication_preview/deformable_nemo-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/deformable_nemo.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="deformable_nemo.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wang2024neural" class="col-sm-9"> <div class="title">Neural textured deformable meshes for robust analysis-by-synthesis</div> <div class="author"> Angtian Wang, <em>Wufei Ma</em>, <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a>, and <a href="https://adamkortylewski.com" rel="external nofollow noopener" target="_blank">Adam Kortylewski</a> </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em> , 2024 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2306.00118" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>We introduce Neural Textured Deformable Meshes (NTDM), which learns a neural mesh model with deformable geometry and enables optimization on both camera parameters and object geometries.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/synthetic_nemo-480.webp 480w,/assets/img/publication_preview/synthetic_nemo-800.webp 800w,/assets/img/publication_preview/synthetic_nemo-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/synthetic_nemo.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="synthetic_nemo.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="yang2024robust" class="col-sm-9"> <div class="title">Robust Category-Level 3D Pose Estimation from Diffusion-Enhanced Synthetic Data</div> <div class="author"> Jiahao Yang, <em>Wufei Ma</em>, Angtian Wang, Xiaoding Yuan, <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a>, and <a href="https://adamkortylewski.com" rel="external nofollow noopener" target="_blank">Adam Kortylewski</a> </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em> , 2024 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2305.16124" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>We introduce SyntheticP3D, a synthetic dataset for object pose estimation, and CC3D that adapts neural mesh models from synthetic to real data.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/animal3d_sm-480.webp 480w,/assets/img/publication_preview/animal3d_sm-800.webp 800w,/assets/img/publication_preview/animal3d_sm-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/animal3d_sm.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="animal3d_sm.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xu2023animal3d" class="col-sm-9"> <div class="title">Animal3D: A Comprehensive Dataset of 3D Animal Pose and Shape</div> <div class="author"> Jiacong Xu, Yi Zhang, Jiawei Peng, <em>Wufei Ma</em>, Artur Jesslen, Pengliang Ji, Qixin Hu, Jiehua Zhang, <a href="https://qihao067.github.io" rel="external nofollow noopener" target="_blank">Qihao Liu</a>, Jiahao Wang, and  others </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision</em> , 2023 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#009f36"> Dataset </abbr> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2308.11737" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://xujiacong.github.io/Animal3D/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://drive.google.com/drive/folders/17KRe8Z7jCZNDeBu45Wx2zS8Yh2tV_t2v?usp=sharing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> </div> <div class="abstract hidden"> <p>Animal3D consists of 3379 images collected from 40 mammal species, high-quality annotations of 26 keypoints, and importantly the pose and shape parameters of the SMAL model.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/oodcv_v2-480.webp 480w,/assets/img/publication_preview/oodcv_v2-800.webp 800w,/assets/img/publication_preview/oodcv_v2-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/oodcv_v2.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="oodcv_v2.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhao2023ood" class="col-sm-9"> <div class="title">OOD-CV-v2: An Extended Benchmark for Robustness to Out-of-Distribution Shifts of Individual Nuisances in Natural Images</div> <div class="author"> Bingchen Zhao, Jiahao Wang, <em>Wufei Ma</em>, Artur Jesslen, Siwei Yang, Shaozuo Yu, Oliver Zendel, Christian Theobalt, <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a>, and <a href="https://adamkortylewski.com" rel="external nofollow noopener" target="_blank">Adam Kortylewski</a> </div> <div class="periodical"> <em>arXiv preprint arXiv:2304.10266</em>, 2023 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#009f36"> Dataset </abbr> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2304.10266" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://bzhao.me/OOD-CV/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>We introduce OOD-CV-v2, a benchmark dataset that includes out-of-distribution examples of 10 object categories in terms of pose, shape, texture, context and the weather conditions, and enables benchmarking of models for image classification, object detection, and 3D pose estimation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/superclevr_eg-480.webp 480w,/assets/img/publication_preview/superclevr_eg-800.webp 800w,/assets/img/publication_preview/superclevr_eg-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/superclevr_eg.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="superclevr_eg.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="li2023super" class="col-sm-9"> <div class="title">Super-CLEVR: A Virtual Benchmark to Diagnose Domain Robustness in Visual Reasoning</div> <div class="author"> Zhuowan Li, Xingrui Wang, Elias Stengel-Eskin, <a href="https://adamkortylewski.com" rel="external nofollow noopener" target="_blank">Adam Kortylewski</a>, <em>Wufei Ma</em>, Benjamin Van Durme , and Alan L Yuille </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> , 2023 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#009f36"> Dataset </abbr> <abbr class="badge rounded" style="background-color:#b509ac"> Vision-Lanugage </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2212.00259" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/Lizw14/Super-CLEVR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We introduce Super-CLEVR, where different factors in VQA domain shifts can be isolated in order that their effects can be studied independently. We propose probabilistic NSVQA (P-NSVQA), which extends NSVQA with uncertainty reasoning.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eccv22_6dpose_small-480.webp 480w,/assets/img/publication_preview/eccv22_6dpose_small-800.webp 800w,/assets/img/publication_preview/eccv22_6dpose_small-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/eccv22_6dpose_small.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eccv22_6dpose_small.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ma2022robust" class="col-sm-9"> <div class="title">Robust Category-Level 6D Pose Estimation with Coarse-to-Fine Rendering of Neural Features</div> <div class="author"> <em>Wufei Ma</em>, Angtian Wang, <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a>, and <a href="https://adamkortylewski.com" rel="external nofollow noopener" target="_blank">Adam Kortylewski</a> </div> <div class="periodical"> <em>In European Conference on Computer Vision</em> , 2022 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2209.05624" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/wufeim/6d_pose_eccv22" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We introduce a coarse-to-fine optimization strategy that utilizes the neural features to estimate a sparse set of 6D object proposals, which are subsequently refined with gradient-based optimization.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/robin2-480.webp 480w,/assets/img/publication_preview/robin2-800.webp 800w,/assets/img/publication_preview/robin2-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/robin2.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="robin2.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhao2022ood" class="col-sm-9"> <div class="title">OOD-CV: A Benchmark for Robustness to Out-of-Distribution Shifts of Individual Nuisances in Natural Images</div> <div class="author"> Bingchen Zhao, Shaozuo Yu, <em>Wufei Ma</em>, Mingxin Yu, Shenxiao Mei, Angtian Wang, Ju He, <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a>, and <a href="https://adamkortylewski.com" rel="external nofollow noopener" target="_blank">Adam Kortylewski</a> </div> <div class="periodical"> <em>In European conference on computer vision</em> , 2022 </div> <div class="periodical"> </div> <div> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2111.14341" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>We introduce ROBIN, a benchmark dataset for diagnosing the robustness of 2D and 3D vision algorithms to individual nuisances in real-world images.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Wufei Ma. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with theme modified from <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>