<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="nnOcJxhf3tCKBL4Jm8iONLUhhtoEPtFYLwoke73tD1c"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Wufei Ma </title> <meta name="author" content="Wufei Ma"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://wufeim.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Wufei</span> Ma </h1> <p class="desc">PhD student. <a href="https://www.cs.jhu.edu" rel="external nofollow noopener" target="_blank">Johns Hopkins University</a>.</p> </header> <article> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/wufeim-min-480.webp 480w,/assets/img/wufeim-min-800.webp 800w,/assets/img/wufeim-min-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/wufeim-min.jpg?2f582bf91571366f86e780b05189e4dd" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="wufeim-min.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p style="font-size:14px"><b><a href="mailto:">Email</a></b> | <b><a href="assets/pdf/wufeima_250807.pdf">CV</a></b></p> <br> <p style="font-size:14px"><b><a href="https://scholar.google.com/citations?user=mYkvHdIAAAAJ" rel="external nofollow noopener" target="_blank">Google Scholar</a></b></p> <br> <p style="font-size:14px"><b><a href="https://x.com/wufeima" rel="external nofollow noopener" target="_blank">Twitter</a></b> </p> </div> </div> <div class="clearfix"> <p>I am a PhD student at <a href="https://www.jhu.edu" rel="external nofollow noopener" target="_blank">Johns Hopkins University</a>, advised by <a href="https://en.wikipedia.org/wiki/Bloomberg_Distinguished_Professorships" rel="external nofollow noopener" target="_blank">Bloomberg Distinguished Professor</a> <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Dr. Alan Yuille</a>. I also work as an applied scientist intern at Amazon FAR (Frontier AI &amp; Robotics).</p> <p>I obtained my B.S. with <i>summa cum laude</i> honor from <a href="https://rpi.edu" rel="external nofollow noopener" target="_blank">Rensselaer Polytechnic Institute</a> in 2020 and I had a double major in Computer Science and Mathematics. During my undergraduate years, I had worked with <a href="https://www.cs.rpi.edu/~yener/" rel="external nofollow noopener" target="_blank">Prof. Bülent Yener</a> on discriminative and generative models for microstructure images and with <a href="https://www.cs.rpi.edu/~xial/" rel="external nofollow noopener" target="_blank">Prof. Lirong Xia</a> on preference learning from natural language.</p> <p>I’ve spent great time at <span><span style="color: #4285F4">G</span><span style="color: #EA4335">o</span><span style="color: #FBBC05">o</span><span style="color: #4285F4">g</span><span style="color: #34A853">l</span><span style="color: #EA4335">e</span> <span style="color:#5f6368">Research</span></span>, <span><img src="assets/img/meta.svg.png" style="height: 12px; margin-bottom: 4px"> Reality Labs</span>, <span><img src="assets/img/microsoft.svg.png" style="height: 12px; margin-bottom: 4px"> Research Asia</span>, <span><img src="assets/img/aws.png" style="height: 12px; margin-bottom: 4px"> CV Science</span>, <span><img src="assets/img/megvii.png" style="height: 12px; margin-bottom: 4px"> Research</span>, and collaborated with many exceptional researchers.</p> <p>I am seeking research-oriented opportunities in industry and would welcome the chance to connect if you think there’s a potential fit.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 12vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Sep 18, 2025</th> <td> One paper accepted to NeurIPS 2025. </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 26, 2025</th> <td> One paper accepted to ICCV 2025. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 26, 2025</th> <td> Two papers accepted to CVPR 2025 (both as <span style="color: red;">highlight</span>). </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 23, 2025</th> <td> One paper accepted to ICLR 2025. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 26, 2024</th> <td> One paper accepted to NeurIPS 2024. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 04, 2024</th> <td> Co-organizing OOD-CV workshop at ECCV 2024. Call for papers at <a href="https://www.ood-cv.org" rel="external nofollow noopener" target="_blank">ood-cv.org</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 01, 2024</th> <td> Two papers accepted to ECCV 2024. </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 10, 2024</th> <td> I will present our Feint6K dataset at WINVU @ CVPR 2024. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 28, 2024</th> <td> One paper accepted to IEEE TMM. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <p class="post-description">see all publications <a href="/publications/" style="color: rgb(87, 151, 210);"><u>here</u></a></p> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/spatialreasoner-480.webp 480w,/assets/img/publication_preview/spatialreasoner-800.webp 800w,/assets/img/publication_preview/spatialreasoner-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/spatialreasoner.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="spatialreasoner.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="ma2025spatialreasoner" class="col-sm-9"> <div class="title">SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning</div> <div class="author"> <em>Wufei Ma</em>, Yu-Cheng Chou, <a href="https://qihao067.github.io" rel="external nofollow noopener" target="_blank">Qihao Liu</a> , <a href="https://xingruiwang.github.io" rel="external nofollow noopener" target="_blank">Xingrui Wang</a>, Celso M de Melo, Jianwen Xie, and <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , 2025 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> <abbr class="badge rounded" style="background-color:#b509ac"> Vision-Lanugage </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://spatial-reasoner.github.io" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Webpage</a> <a href="http://arxiv.org/abs/2504.20024" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>We introduce SpatialReasoner, a novel large vision-language model (LVLM) that address 3D spatial reasoning with explicit 3D representations shared between stages – 3D perception, computation, and reasoning. Explicit 3D representations provide a coherent interface that supports advanced 3D spatial reasoning and enable us to study the factual errors made by LVLMs.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/3dsrbench-480.webp 480w,/assets/img/publication_preview/3dsrbench-800.webp 800w,/assets/img/publication_preview/3dsrbench-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/3dsrbench.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="3dsrbench.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="Ma_2025_ICCV" class="col-sm-9"> <div class="title">3DSRBench: A Comprehensive 3D Spatial Reasoning Benchmark</div> <div class="author"> <em>Wufei Ma</em> , Haoyu Chen, <a href="https://openreview.net/profile?id=~Guofeng_Zhang4" rel="external nofollow noopener" target="_blank">Guofeng Zhang</a>, Celso M de Melo, <a href="https://beckschen.github.io" rel="external nofollow noopener" target="_blank">Jieneng Chen</a>, and <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a> </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em> , Oct 2025 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> <abbr class="badge rounded" style="background-color:#b509ac"> Vision-Lanugage </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://3dsrbench.github.io" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Webpage</a> <a href="http://arxiv.org/abs/2412.07825" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>We present 3DSRBench, a comprehensive 3D spatial reasoning benchmark.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/3dvlm-teaser2-2-480.webp 480w,/assets/img/publication_preview/3dvlm-teaser2-2-800.webp 800w,/assets/img/publication_preview/3dvlm-teaser2-2-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/3dvlm-teaser2-2.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="3dvlm-teaser2-2.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="ma2025spatialllm" class="col-sm-9"> <div class="title">SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models</div> <div class="author"> <em>Wufei Ma</em>, Luoxin Ye, Celso M de Melo, <a href="https://beckschen.github.io" rel="external nofollow noopener" target="_blank">Jieneng Chen</a>, and <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a> </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em> , Oct 2025 </div> <div class="periodical"> </div> <div class="periodical"> <span style="color:#e74c3c"><b>(Highlight, 3.0%)</b></span> </div> <div> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> <abbr class="badge rounded" style="background-color:#b509ac"> Vision-Lanugage </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://3d-spatial-reasoning.github.io/spatial-llm/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Webpage</a> <a href="http://arxiv.org/abs/2505.00788" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>We systematically study the impact of 3D-informed data, architecture, and training setups and present SpatialLLM, an LMM with advanced 3D spatial reasoning abilities.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/imagenet3d_logo-480.webp 480w,/assets/img/publication_preview/imagenet3d_logo-800.webp 800w,/assets/img/publication_preview/imagenet3d_logo-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/imagenet3d_logo.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="imagenet3d_logo.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="ma2024imagenet3d" class="col-sm-9"> <div class="title">ImageNet3D: Towards General-Purpose Object-Level 3D Understanding</div> <div class="author"> <em>Wufei Ma</em>, <a href="https://openreview.net/profile?id=~Guofeng_Zhang4" rel="external nofollow noopener" target="_blank">Guofeng Zhang</a>, <a href="https://qihao067.github.io" rel="external nofollow noopener" target="_blank">Qihao Liu</a>, <a href="https://scholar.google.com/citations?user=SU6ooAQAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Guanning Zeng</a>, <a href="https://adamkortylewski.com" rel="external nofollow noopener" target="_blank">Adam Kortylewski</a> , <a href="https://www.cs.jhu.edu/~yyliu/" rel="external nofollow noopener" target="_blank">Yaoyao Liu</a>, and <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , Oct 2024 </div> <div class="periodical"> </div> <div> <abbr class="badge rounded" style="background-color:#009f36"> Dataset </abbr> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://imagenet3d.github.io" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Webpage</a> <a href="http://arxiv.org/abs/2406.09613" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/wufeim/imagenet3d" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> <a href="https://github.com/wufeim/imagenet3d_exp" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We present ImageNet3D, a large dataset for general-purpose object-level 3D understanding.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/feint6k-480.webp 480w,/assets/img/publication_preview/feint6k-800.webp 800w,/assets/img/publication_preview/feint6k-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/feint6k.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="feint6k.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="ma2024rethinking" class="col-sm-9"> <div class="title">Rethinking Video-Text Understanding: Retrieval from Counterfactually Augmented Data</div> <div class="author"> <em>Wufei Ma</em>, <a href="https://sites.google.com/view/kaisqu/" rel="external nofollow noopener" target="_blank">Kai Li</a>, <a href="https://scholar.google.com/citations?user=h8bGMF4AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Zhongshi Jiang</a>, <a href="http://www.cs.umd.edu/~mmeshry/" rel="external nofollow noopener" target="_blank">Moustafa Meshry</a>, <a href="https://qihao067.github.io" rel="external nofollow noopener" target="_blank">Qihao Liu</a>, <a href="https://csrhddlam.github.io" rel="external nofollow noopener" target="_blank">Huiyu Wang</a>, <a href="https://scholar.google.com/citations?user=AliuYd0AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Christian Häne</a>, and <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a> </div> <div class="periodical"> <em>In European Conference on Computer Vision</em> , Oct 2024 </div> <div class="periodical"> </div> <div class="periodical"> <span style="color:#e74c3c"><b>(Strong Double Blind)</b></span> </div> <div> <abbr class="badge rounded" style="background-color:#009f36"> Dataset </abbr> <abbr class="badge rounded" style="background-color:#b509ac"> Vision-Lanugage </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://feint6k.github.io" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Webpage</a> <a href="http://arxiv.org/abs/2407.13094" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/facebookresearch/feint6k" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> </div> <div class="abstract hidden"> <p>We propose a novel task, retrieval from counterfacually augmented data, and a dataset, Feint6K, for video-text understanding.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/3ddst_compressed-480.webp 480w,/assets/img/publication_preview/3ddst_compressed-800.webp 800w,/assets/img/publication_preview/3ddst_compressed-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/3ddst_compressed.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="3ddst_compressed.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="ma2024generating" class="col-sm-9"> <div class="title">Generating Images with 3D Annotations Using Diffusion Models</div> <div class="author"> <em>Wufei Ma<sup>*</sup></em>, <a href="https://qihao067.github.io" rel="external nofollow noopener" target="_blank">Qihao Liu<sup>*</sup></a> , <a href="https://jiahaoplus.github.io" rel="external nofollow noopener" target="_blank">Jiahao Wang<sup>*</sup></a> , <a href="https://angtianwang.github.io" rel="external nofollow noopener" target="_blank">Angtian Wang</a>, <a href="https://www.xiaodingyuan.com" rel="external nofollow noopener" target="_blank">Xiaoding Yuan</a> , Yi Zhang, <a href="https://scholar.google.com/citations?user=ucb6UssAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Zihao Xiao</a>, <a href="https://openreview.net/profile?id=~Guofeng_Zhang4" rel="external nofollow noopener" target="_blank">Guofeng Zhang</a> , Beijia Lu, Ruxiao Duan, Yongrui Qi, <a href="https://adamkortylewski.com" rel="external nofollow noopener" target="_blank">Adam Kortylewski</a> , <a href="https://www.cs.jhu.edu/~yyliu/" rel="external nofollow noopener" target="_blank">Yaoyao Liu</a>, and <a href="https://www.cs.jhu.edu/~ayuille/" rel="external nofollow noopener" target="_blank">Alan Yuille</a> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* equal contribution"> </i> </div> <div class="periodical"> <em>In The Twelfth International Conference on Learning Representations</em> , Oct 2024 </div> <div class="periodical"> </div> <div class="periodical"> <span style="color:#e74c3c"><b>(Spotlight, 5%)</b></span> </div> <div> <abbr class="badge rounded" style="background-color:#009f36"> Dataset </abbr> <abbr class="badge rounded" style="background-color:#00369f"> 3D Vision </abbr> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2306.08103" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/wufeim/DST3D" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We propose 3D-DST that generates synthetic data with 3D groundtruth by incorporating 3D geomeotry control into diffusion models. With our diverse prompt generation, we effectively improve both in-distribution (ID) and out-of-distribution (OOD) performance for various 2D and 3D vision tasks.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Wufei Ma. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with theme modified from <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-158881522-2"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-158881522-2");</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>